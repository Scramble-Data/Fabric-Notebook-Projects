{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
   import os
import textwrap

# 0. Inställningar
package_name = 'super_utils'
target_path = "abfss://path"

code_content = textwrap.dedent(code).strip()

# 1. Skapa katalogstruktur lokalt
os.makedirs(package_name, exist_ok=True)

# 2. Skriv functions.py
with open(f'{package_name}/functions.py', 'w', encoding='utf-8') as f:
    f.write(code_content)

# 3. Skapa __init__.py
with open(f'{package_name}/__init__.py', 'w', encoding='utf-8') as f:
    f.write("from .functions import *")

# 4. Skapa setup.py
setup_content = f"""
from setuptools import setup, find_packages
setup(
    name='{package_name}',
    version='0.1',
    packages=find_packages(),
    install_requires=['pyspark'],
)
"""
with open('setup.py', 'w', encoding='utf-8') as f:
    f.write(setup_content)

# 5. Bygg wheel-filen
!python setup.py bdist_wheel

# 6. Kopiera till OneLake och installera
wheel_file = [f for f in os.listdir('dist') if f.endswith('.whl')][0]
local_wheel_path = f"dist/{wheel_file}"
remote_wheel_path = f"{target_path}/{wheel_file}"

# Kopiera filen till Lakehouse
from notebookutils import mssparkutils
mssparkutils.fs.cp(f"file://{os.getcwd()}/{local_wheel_path}", remote_wheel_path)

# Installera direkt från den lokala filen
!pip install --force-reinstall {local_wheel_path}

print(f"Wheel sparad till: {remote_wheel_path}")
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Python)",
   "language": "python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
